<!-- 
  이 파일은 Reveal.js 기준
  21: 백엔드 - 왜 Google Gemini를 선택했는가? (Why)
  슬라이드입니다. 
-->
<section data-part-title="Part 3. ⚙️ 백엔드 (FastAPI)" data-menu-title="Backend (Why Gemini?)">
  <section data-menu-title="Why Gemini?">
    <h3>왜 Google Gemini를 선택했는가? 🧠</h3>
    <p>
      AI 챗봇의 성능을 좌우하는 LLM(거대 언어 모델)으로, 저희는 여러 선택지 중
      <strong>Google의 Gemini 2.5 Flash</strong> 모델을 선택했습니다. <br />
      가장 큰 이유는 바로 <strong>'최고의 가성비'</strong>였습니다.
    </p>
    <div
      style="
        margin-top: 15px;
        text-align: center;
        height: 105vh;
        display: flex;
        align-items: center;
        justify-content: center;
      "
    >
      <img
        src="assets/gemini-benchmark.jpeg"
        alt="LLM 벤치마크 비교표"
        style="
          max-width: 100%;
          max-height: 100%;
          object-fit: contain;
          border-radius: 12px;
        "
      />
    </div>
    <aside class="notes">
      저희 AI 챗봇의 핵심 두뇌 역할을 하는 LLM(거대 언어 모델)을 선택할 때,
      저희의 기준은 명확했습니다. 바로 '최고의 가성비'입니다.
      <br /><br />
      이 벤치마크 표를 보시면, 저희가 선택한
      <strong>Gemini 2.5 Flash</strong> 모델은 다른 고가의 모델(OpenAI o4-mini,
      Claude 3.7 Sonnet 등)과 비교했을 때, 여러 추론 및 지식 평가 항목에서
      대등하거나 때로는 더 나은 성능을 보여줍니다. <br /><br />
      특히 주목할 점은 <strong>가격</strong>입니다. Gemini 2.5 Flash의 토큰당
      가격은 경쟁 모델 대비 <strong>수 배에서 수십 배 저렴</strong>합니다.
      <br /><br />
      즉, 저희는 <strong>'적절한 비용으로 최고 수준의 성능'</strong>을 얻을 수
      있는 가장 합리적인 선택지로 Gemini 2.5 Flash를 채택했습니다. 이는 한정된
      자원으로 운영해야 하는 저희 프로젝트에 매우 중요한 결정이었습니다.
    </aside>
  </section>
</section>
